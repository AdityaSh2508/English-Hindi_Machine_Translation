{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97a6f18-16e8-4b37-aeea-0a757cc1cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages for the project\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c4026ce-5c11-447b-8d3e-2a7c1a15b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data generator & preparation\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "import spacy\n",
    "import sys\n",
    "from indicnlp import common\n",
    "from indicnlp.tokenize import indic_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3266a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer using spaCy\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define English tokenizer\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e4a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hindi tokenizer using Indic NLP\n",
    "def tokenize_hindi(text):\n",
    "    return [tok for tok in indic_tokenize.trivial_tokenize(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0ba34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Field objects for English and Hindi text\n",
    "english_txt = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "hindi_txt = Field(tokenize=tokenize_hindi, init_token=\"<sos>\", eos_token=\"<eos>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "286747ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data fields for loading CSV files\n",
    "data_fields = [('eng_text', english_txt), ('hindi_text', hindi_txt)]\n",
    "\n",
    "# Load training and validation datasets\n",
    "train_dt, val_dt = TabularDataset.splits(\n",
    "    path='./', \n",
    "    train='train.csv', \n",
    "    validation='val.csv', \n",
    "    format='csv', \n",
    "    fields=data_fields\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2cb0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary for English and Hindi text\n",
    "english_txt.build_vocab(train_dt, max_size=10000, min_freq=2)\n",
    "hindi_txt.build_vocab(train_dt, max_size=10000, min_freq=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10daabb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU Found\")\n",
    "\n",
    "# Set model training parameters\n",
    "save_model = True\n",
    "num_epochs = 1\n",
    "learning_rate = 5e-4\n",
    "batch_size = 96\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c08c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterators for training and validation data\n",
    "train_iter = BucketIterator(train_dt, batch_size=batch_size, sort_key=lambda x: len(x.eng_text), shuffle=True)\n",
    "val_iter = BucketIterator(val_dt, batch_size=batch_size, sort_key=lambda x: len(x.eng_text), shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54dbeb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10004\n",
      "10004\n"
     ]
    }
   ],
   "source": [
    "from transformer import Transformer\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size = len(english_txt.vocab)\n",
    "trg_vocab_size = len(hindi_txt.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 10000\n",
    "forward_expansion = 4\n",
    "src_pad_idx = english_txt.vocab.stoi[\"<pad>\"]\n",
    "trg_pad_idx = 0\n",
    "\n",
    "# Initialize the Transformer model\n",
    "model = Transformer(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    trg_vocab_size=trg_vocab_size,\n",
    "    src_pad_idx=src_pad_idx,\n",
    "    trg_pad_idx=trg_pad_idx,\n",
    "    embed_size=embedding_size,\n",
    "    num_layers=num_layers,\n",
    "    forward_expansion=forward_expansion,\n",
    "    heads=num_heads,\n",
    "    dropout=dropout,\n",
    "    device=device,\n",
    "    max_len=max_len\n",
    ").to(device)\n",
    "\n",
    "print(len(english_txt.vocab))\n",
    "print(len(hindi_txt.vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a1c43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer, learning rate scheduler, and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True)\n",
    "pad_idx = hindi_txt.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9458201",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/13768 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4468\\2807704076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_vocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adity\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Translation Model\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, trg)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0msrc_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_src_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mtrg_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_trg_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0menc_src\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_src\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adity\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Translation Model\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adity\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Translation Model\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, value, key, query, mask)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mattention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mforward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adity\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Translation Model\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, mask)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mvalue_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adity\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adity\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adity\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "loss_tracker = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    loop = tqdm(enumerate(train_iter), total=len(train_iter))\n",
    "    \n",
    "    for batch_idx, batch in loop:\n",
    "        inp_data = batch.eng_text.permute(-1, -2).to(device)\n",
    "        target = batch.hindi_text.permute(-1, -2).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(inp_data, target[:, :-1])\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.reshape(-1, trg_vocab_size), target[:, 1:].reshape(-1)) - 1\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # Calculate mean training loss\n",
    "    train_mean_loss = sum(losses) / len(losses)\n",
    "    train_losses.append(train_mean_loss)\n",
    "    \n",
    "    # Get and track the learning rate\n",
    "    learning_rate = optimizer.param_groups[0]['lr']\n",
    "    learning_rates.append(learning_rate)\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step(train_mean_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_losses_epoch = []\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, val_batch in tqdm(enumerate(val_iter), total=len(val_iter)):\n",
    "            val_inp_data = val_batch.eng_text.permute(-1, -2).to(device)\n",
    "            val_target = val_batch.hindi_text.permute(-1, -2).to(device)\n",
    "            val_output = model(val_inp_data, val_target[:, :-1])\n",
    "            val_loss = criterion(val_output.reshape(-1, trg_vocab_size), val_target[:, 1:].reshape(-1)) - 1\n",
    "            val_losses_epoch.append(val_loss.item())\n",
    "            \n",
    "        val_mean_loss = sum(val_losses_epoch) / len(val_losses_epoch)\n",
    "        val_losses.append(val_mean_loss)\n",
    "\n",
    "    # Save best model\n",
    "    loss_tracker.append(val_mean_loss)\n",
    "    if save_model and val_mean_loss == np.min(loss_tracker):\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, 'best_model.pth')\n",
    "        \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]: train_loss={train_mean_loss}; val_loss={val_mean_loss}; \"\n",
    "          f\"learning_rate={learning_rate}\")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2256d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English tokenizer from spaCy\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define English and Hindi tokenizers\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "def tokenize_hindi(text):\n",
    "    return [tok for tok in indic_tokenize.trivial_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f264df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fields for English and Hindi text\n",
    "english_txt = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "hindi_txt = Field(tokenize=tokenize_hindi, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "# Load training and validation datasets\n",
    "data_fields = [('eng_text', english_txt), ('hindi_text', hindi_txt)]\n",
    "train_dt, val_dt = TabularDataset.splits(path='C:/Translation Model/', train='train.csv', validation='val.csv', format='csv', fields=data_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(sentence, model, src_field, src_tokenizer, trg_field, trg_vcb_sz, k, max_ts=50, device=\"cpu\"):\n",
    "    # Tokenize and preprocess input sentence\n",
    "    sentence_tok = src_tokenizer(sentence)\n",
    "    sentence_tok.insert(0, src_field.init_token)\n",
    "    sentence_tok.append(src_field.eos_token)\n",
    "\n",
    "    # Convert sentence to tensor of indices\n",
    "    src_tok = torch.tensor([src_field.vocab.stoi[token] for token in sentence_tok], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    trg_tok = torch.tensor([trg_field.vocab.stoi[trg_field.init_token]], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    eos_token = trg_field.vocab.stoi[trg_field.eos_token]\n",
    "    trans_store = {}\n",
    "\n",
    "    store_seq_id = None\n",
    "    store_seq_prob = None\n",
    "    \n",
    "    for ts in range(max_ts):\n",
    "        if ts == 0:\n",
    "            with torch.no_grad():\n",
    "                out = model(src_tok, trg_tok)\n",
    "            topk = torch.topk(torch.log(torch.softmax(out, dim=-1)), dim=-1, k=k)\n",
    "            seq_id = trg_tok.expand(k, -1).clone()\n",
    "            seq_id = torch.cat([seq_id, topk.indices.squeeze().unsqueeze(1)], dim=1)\n",
    "            seq_prob = topk.values.squeeze()\n",
    "            \n",
    "            eos_mask = seq_id[:, -1] == eos_token\n",
    "            if eos_mask.any():\n",
    "                trans_store.update({seq_prob[i].item(): seq_id[i] for i in range(k) if eos_mask[i]})\n",
    "                seq_id = seq_id[~eos_mask]\n",
    "                seq_prob = seq_prob[~eos_mask]\n",
    "            store_seq_id = seq_id.to(device)\n",
    "            store_seq_prob = seq_prob.to(device)\n",
    "        else:\n",
    "            # Expand src_tok to match number of sequences in store_seq_id\n",
    "            src_expanded = src_tok.expand(store_seq_id.shape[0], -1).to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(src_expanded, store_seq_id)\n",
    "            out = torch.log(torch.softmax(out[:, -1, :], dim=-1))\n",
    "\n",
    "            all_comb = (store_seq_prob.unsqueeze(1) + out).view(-1)\n",
    "            all_comb_idx = torch.cartesian_prod(\n",
    "                torch.arange(store_seq_id.shape[0]), torch.arange(trg_vcb_sz)\n",
    "            ).to(device)\n",
    "            topk = torch.topk(all_comb, k=k)\n",
    "            top_seq_idx = all_comb_idx[topk.indices]\n",
    "            seq_prob = topk.values\n",
    "\n",
    "            new_seq_id = store_seq_id[top_seq_idx[:, 0]]\n",
    "            new_seq_id = torch.cat([new_seq_id, top_seq_idx[:, 1].unsqueeze(1)], dim=1)\n",
    "\n",
    "            eos_mask = new_seq_id[:, -1] == eos_token\n",
    "            if eos_mask.any():\n",
    "                trans_store.update({seq_prob[i].item(): new_seq_id[i] for i in range(k) if eos_mask[i]})\n",
    "                new_seq_id = new_seq_id[~eos_mask]\n",
    "                seq_prob = seq_prob[~eos_mask]\n",
    "            store_seq_id = new_seq_id.to(device)\n",
    "            store_seq_prob = seq_prob.to(device)\n",
    "\n",
    "        if len(trans_store) >= k:\n",
    "            break\n",
    "\n",
    "    if len(trans_store) == 0:\n",
    "        best_translation = store_seq_id[0]\n",
    "    else:\n",
    "        best_translation = trans_store[max(trans_store)]\n",
    "\n",
    "    return \" \".join([trg_field.vocab.itos[w] for w in best_translation[1:] if w != eos_token])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary after modifying sequence length\n",
    "english_txt.build_vocab(train_dt, max_size=10000, min_freq=2)\n",
    "hindi_txt.build_vocab(train_dt, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de466d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample English sentence to translate\n",
    "sample_sentence = \"Indian government takes good care of the minorities\"\n",
    "\n",
    "# Run beam search to get the translation\n",
    "translated_text = beam_search(\n",
    "    sentence=sample_sentence,\n",
    "    model=model,  # Make sure 'model' is your trained model\n",
    "    src_field=english_txt,\n",
    "    src_tokenizer=tokenize_eng,\n",
    "    trg_field=hindi_txt,\n",
    "    trg_vcb_sz=10000,\n",
    "    k=5,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Display the translated text\n",
    "print(\"English Sentence:\", sample_sentence)\n",
    "print(\"Translated Hindi Sentence:\", translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae92096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
